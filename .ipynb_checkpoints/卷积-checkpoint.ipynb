{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolutional**\n",
    "\n",
    "**Weight sharing 权值共享**\n",
    "\n",
    "        卷积窗口\n",
    "**pooling: max pooling, avg pooling**　`layer=nn.MaxPool2d(2,stride=2)` / `F.avg_pool2d(x,2,stride=2)`\n",
    "\n",
    "**Subsampling 隔行采样　**\n",
    " \n",
    "**插值**　interpolate `F.interpolate(x,scale_factor=2,model='nearest')` scale_factor:放大倍数\n",
    "\n",
    "**ReLU**  `nn.ReLU(inplace=True)`/ `F.relu(x)`\n",
    "\n",
    "**Batch normalizing**  `nn.BatchNorm2d()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积网络发展"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|||\n",
    "|-|-|\n",
    "| letNet-5| <img src=\"./photo/lenet.png\" width = \"500\" height = \"500\" alt=\"图片名称\" align=center />  |  \n",
    "|AlexNet|<img src=\"./photo/alexnet.png\" width = \"500\" height = \"500\" alt=\"图片名称\" align=center />|\n",
    "|VGG|<img src=\"./photo/vgg.png\" width = \"500\" height = \"500\" alt=\"图片名称\" align=center />|\n",
    "|GoogLeNet|<img src=\"./photo/googlenet.png\" width = \"500\" height = \"500\" alt=\"图片名称\" align=center />| \n",
    "|ResNet|<img src=\"./photo/resnet.png\" width = \"500\" height = \"500\" alt=\"图片名称\" align=center />|\n",
    "|DenseNet|<img src=\"./photo/DenseNet.png\" width = \"500\" height = \"500\" alt=\"图片名称\" align=center />|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 维度表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入：　[num(batch), input_channel, height_size, weight_size]\n",
    "\n",
    "卷积（weight）：  [kernel_num, input_channe, kernel_size, kernel_size]\n",
    "\n",
    "生成：　[num(batch), kernel_num, image_generate, image_generate]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 14, 14])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1,1,28,28)\n",
    "layer = nn.Conv2d(1,3,kernel_size=3,stride=1,padding=0)\n",
    "out = layer.forward(x) # torch.Size([1, 3, 26, 26])\n",
    "\n",
    "layer = nn.Conv2d(1,3,kernel_size=3,stride=1,padding=1)\n",
    "out = layer.forward(x) # torch.Size([1, 3, 28, 28])\n",
    "\n",
    "layer = nn.Conv2d(1,3,kernel_size=3,stride=2,padding=1)\n",
    "out = layer.forward(x) # torch.Size([1, 3, 14, 14])\n",
    "\n",
    "out = layer(x) # __call__ 使用__call__()　会有很多　hook 建议使用__call()，不使用 forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 3, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.weight.shape  # torch.Size([3, 1, 3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.bias.shape # torch.Size([3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 26, 26])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  \n",
    "x = torch.randn(1,3,28,28)\n",
    "w = torch.rand(16,3,5,5)\n",
    "b = torch.rand(16)\n",
    "\n",
    "out = F.conv2d(x,w,b,stride=1,padding=1)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./xxx.png\" width = \"300\" height = \"200\" alt=\"图片名称\" align=center />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| batch1 |batch2  |  \n",
    "|:-:| :-: | \n",
    "|  <img src=\"./photo/batch1.png\" width = \"300\" height = \"300\" alt=\"图片名称\" align=center /> |  <img src=\"./photo/batch2.png\" width = \"300\" height = \"300\" alt=\"图片名称\" align=center /> | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0499, 0.0500, 0.0500, 0.0502, 0.0500, 0.0501, 0.0500, 0.0499, 0.0501,\n",
      "        0.0500, 0.0501, 0.0500, 0.0499, 0.0500, 0.0500, 0.0499])\n",
      "tensor([0.9083, 0.9083, 0.9084, 0.9083, 0.9083, 0.9083, 0.9083, 0.9084, 0.9083,\n",
      "        0.9083, 0.9083, 0.9083, 0.9084, 0.9083, 0.9083, 0.9084])\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand(100,16,784) # x　01均匀分布 mean=0.5\n",
    "layer = torch.nn.BatchNorm1d(16)\n",
    "\n",
    "out = layer(x)\n",
    "\n",
    "print(layer.running_mean)\n",
    "print(layer.running_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': True, '_parameters': OrderedDict([('weight', Parameter containing:\n",
       "               tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "                      requires_grad=True)), ('bias', Parameter containing:\n",
       "               tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                      requires_grad=True))]), '_buffers': OrderedDict([('running_mean',\n",
       "               tensor([ 0.0103, -0.0193,  0.0051,  0.0372, -0.0157, -0.0044,  0.0131, -0.0189,\n",
       "                       -0.0066, -0.0159,  0.0135, -0.0042,  0.0101,  0.0024, -0.0170,  0.0135])),\n",
       "              ('running_var',\n",
       "               tensor([0.9728, 0.9797, 1.0306, 1.0123, 0.9797, 1.0126, 0.9928, 0.9681, 1.0662,\n",
       "                       0.9958, 1.0296, 1.0192, 0.9840, 0.9941, 1.0203, 0.9893])),\n",
       "              ('num_batches_tracked',\n",
       "               tensor(1))]), '_backward_hooks': OrderedDict(), '_forward_hooks': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_modules': OrderedDict(), 'num_features': 16, 'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.randn(1,16,7,7)\n",
    "layer = torch.nn.BatchNorm2d(16)\n",
    "\n",
    "out = layer(x)\n",
    "\n",
    "layer.weight.shape # torch.Size([16])\n",
    "\n",
    "vars(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./photo/residual.png\" width = \"700\" height = \"700\" alt=\"图片名称\" align=center />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlk(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out):\n",
    "        self.conv1 = nn.Conv2d(ch_in,ch_out,kernel_size=3,stride=1,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(ch_out)\n",
    "        self.conv2 = nn.Conv2d(ch_out,ch_out,kernel_size=3,stride=1,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(ch_out)\n",
    "        \n",
    "        self.extra = nn.Sequential()\n",
    "        if ch_out != ch_in:\n",
    "            # [b,ch_in,h,w] => [b,ch_out,h,w]\n",
    "            self.extra = nn.Sequential(\n",
    "                nn.Conv2d(ch_in,ch_out,kernel_size=1,stride=1),\n",
    "                nn.BatchNorm2d(ch_out)\n",
    "            )\n",
    "    def forward(self,x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = self.extra(x) + out\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Module的好处"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.embed current layers**: Linear,ReLU,Sigmoid,Conv2d,ConvTransposed2d,Dropout,etc.\n",
    "\n",
    "**2. Container: net(x)**\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1,32,5,1,1),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(32)\n",
    "        )\n",
    "        \n",
    "**3. parameters**\n",
    "\n",
    "        list(net.parameters())[0].shape\n",
    "        list(net.named_parameters())[0] /items()\n",
    "\n",
    "**4. modules**\n",
    "        \n",
    "        modules: all nodes\n",
    "        children: direct children\n",
    "        \n",
    "**5. to(device)**\n",
    "\n",
    "        device = torch.device('cude')\n",
    "        net = Net()\n",
    "        net.to(device)　# net.to(device) 返回net\n",
    "        # 对于tensor.to(device)来说，会返回tensor_gpu变量。\n",
    "\n",
    "**6. save and load**\n",
    "\n",
    "        net = Net()\n",
    "        net.load_state_dict(torch.load('cpkt.mdl'))\n",
    "        torch.save(net.state_dict(),'cpkt.mkl')\n",
    "        \n",
    "**7. train/test**\n",
    "\n",
    "        # train\n",
    "        net.train()\n",
    "        # test\n",
    "        net.eval()\n",
    "        \n",
    "**8. implement own layer**\n",
    "\n",
    "```python\n",
    "# 卷积层[b,256,3,3]　-> 全连接层　[b,256*3*3]\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten,self).__init__()\n",
    "    \n",
    "    def forward(self,input):\n",
    "        return input.view(input.size(0),-1)\n",
    "    \n",
    "class TestNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(TestNet,self).__init__()\n",
    "        # Sequential传入的之可以为class,不能为function F.relu()\n",
    "        self.net = nn.Sequential(nn.Conv2d(1,16,stride=1,padding=1),\n",
    "                                 nn.MaxPool2d(2,2),\n",
    "                                 Flatten(),\n",
    "                                 nn.Linear(1*14*14,10))\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "```\n",
    "\n",
    "**own linear layer**\n",
    "```python\n",
    "class MyLinear(nn.Module):\n",
    "    \n",
    "    def __init__(self,inp,outp):\n",
    "        super(MyLinear,self).__init__()\n",
    "        \n",
    "        # requires_grad = True\n",
    "        self.w = nn.Parameter(torch.randn(outp,inp))\n",
    "        self.b = nn.Parameter(torch.randn(outp))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = x @ self.w.t() + self.b\n",
    "        return x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data argumentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data',train=True,download=False,\n",
    "                  transform=transforms.Compose([\n",
    "                      transforms.RandomHorizontalFlip(), #翻转\n",
    "                      transforms.RandomVerticalFlip(),\n",
    "                      \n",
    "#                       transforms.RandomRotation(15), # 旋转\n",
    "                      transforms.RandomRotation([90,180]),\n",
    "                      \n",
    "                      transforms.Resize([32,32]),# 缩放 scale\n",
    "\n",
    "                      transforms.RandomCrop([28,28]), # 随机裁剪\n",
    "                      transforms.ToTensor(),\n",
    "                      # transforms.Normalize((0.1307,0.3081))\n",
    "                  ])),\n",
    "    batch_size=batch_size,shuffle=True\n",
    ")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
